{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4995d1e-b641-4ae3-9481-1685f2955a3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- payment_id: string (nullable = true)\n |-- date: string (nullable = true)\n |-- amount: string (nullable = true)\n |-- rider_id: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Drop the table if it exists to avoid errors\n",
    "spark.sql('DROP TABLE IF EXISTS payments_table')\n",
    "\n",
    "# Create the table if it does not exist, specifying the correct location\n",
    "spark.sql('''\n",
    "CREATE TABLE IF NOT EXISTS payments_table\n",
    "USING delta\n",
    "LOCATION 'dbfs:/FileStore/demo/delta_payments'\n",
    "''')\n",
    "\n",
    "# Load the table as a DataFrame\n",
    "df = spark.table('payments_table')\n",
    "\n",
    "# Print the schema of the DataFrame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed5e769a-00d6-45d0-97f5-8a51cb532d6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- trip_id: string (nullable = true)\n |-- rideable_id: string (nullable = true)\n |-- started_at: string (nullable = true)\n |-- ended_at: string (nullable = true)\n |-- start_station_id: string (nullable = true)\n |-- end_station_id: string (nullable = true)\n |-- rider_id: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Drop the table if it exists to avoid errors\n",
    "spark.sql('DROP TABLE IF EXISTS trip_table')\n",
    "\n",
    "# Create the table if it does not exist, specifying the correct location\n",
    "spark.sql('''\n",
    "CREATE TABLE IF NOT EXISTS trip_table\n",
    "USING delta\n",
    "LOCATION 'dbfs:/FileStore/demo/delta_trip'\n",
    "''')\n",
    "\n",
    "# Load the table as a DataFrame\n",
    "df = spark.table('trip_table')\n",
    "\n",
    "# Print the schema of the DataFrame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d729905-2f45-421a-8457-677a0363b81c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- station_id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- latitude: string (nullable = true)\n |-- longitude: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop the table if it exists to avoid errors\n",
    "spark.sql('DROP TABLE IF EXISTS stations_table')\n",
    "\n",
    "# Create the table if it does not exist, specifying the correct location\n",
    "spark.sql('''\n",
    "CREATE TABLE IF NOT EXISTS stations_table\n",
    "USING delta\n",
    "LOCATION 'dbfs:/FileStore/demo/delta_stations'\n",
    "''')\n",
    "\n",
    "# Load the table as a DataFrame\n",
    "df = spark.table('stations_table')\n",
    "\n",
    "# Print the schema of the DataFrame\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb7a29fb-d7d3-46f5-81ff-5f571bb502c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- station_id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- latitude: string (nullable = true)\n |-- longitude: string (nullable = true)\n\nroot\n |-- rider_id: string (nullable = true)\n |-- first_name: string (nullable = true)\n |-- last_name: string (nullable = true)\n |-- address: string (nullable = true)\n |-- birthday: string (nullable = true)\n |-- account_start_date: string (nullable = true)\n |-- account_end_date: string (nullable = true)\n |-- is_member: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop the table if it exists to avoid errors\n",
    "spark.sql('DROP TABLE IF EXISTS trip_table')\n",
    "\n",
    "# Create the table if it does not exist, specifying the correct location\n",
    "spark.sql('''\n",
    "CREATE TABLE IF NOT EXISTS riders_table2\n",
    "USING delta\n",
    "LOCATION 'dbfs:/FileStore/demo/delta_riders2'\n",
    "''')\n",
    "\n",
    "# Load the table as a DataFrame\n",
    "df = spark.table('stations_table')\n",
    "\n",
    "# Print the schema of the DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "df=spark.read.format('delta').load('dbfs:/FileStore/demo/delta_riders2')\n",
    "df.write.format('delta').mode('overwrite').option('mergeSchema', 'true').saveAsTable('riders_table2')\n",
    "schema_string = df._jdf.schema().treeString()\n",
    "print(schema_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcbdaf8e-ab63-495d-8cf7-2210c0b26007",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-11-24 06:05:49",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}